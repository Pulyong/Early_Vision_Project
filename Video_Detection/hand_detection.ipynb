{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"mount_file_id":"1qeYHleUbQuWdT2zAQCvyggT5_v5RmbMV","authorship_tag":"ABX9TyMpO6JK0l4ePJlOqYP868vy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2C79KLPAlYfO"},"outputs":[],"source":["import cv2\n","from google.colab.patches import cv2_imshow\n","import numpy as np"]},{"cell_type":"code","source":["from IPython.display import HTML\n","from base64 import b64encode\n","video_path = '/content/drive/MyDrive/Konkuk_CV/영상1.mp4'\n","\n","mp4 = open(video_path,'rb').read()\n","decoded_vid = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(f'<video width=400 controls><source src={decoded_vid} type=\"video/mp4\"></video>')"],"metadata":{"id":"28T7OtKPm9LF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Hand_Detection():\n","\n","    def __init__(self,path):\n","        self.path = path\n","        self.frames = list()\n","        self.detected_frames = list()\n","        self.cap = None\n","\n","    def video_to_frames(self):\n","        self.cap = cv2.VideoCapture(self.path)\n","        while self.cap.isOpened():\n","            run, frame = self.cap.read()\n","            if not run:\n","                break\n","            img = cv2.cvtColor(frame, cv2.IMREAD_COLOR)\n","            self.frames.append(img)\n","\n","\n","\n","    def frames_rgb_to_ycr(self,frames):\n","        g_frames = []\n","        for frame in frames:\n","            g_frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2YCR_CB))\n","        return np.array(g_frames, dtype='uint8')\n","\n","    def connect_components(self,frames, original_frames, area_min):\n","        for k, frame in enumerate(frames):\n","            cnt, labels, stats, centroids = cv2.connectedComponentsWithStats(frame)\n","            for i in range(1, cnt):\n","                (x, y, w, h, area) = stats[i]\n","                cent_x,cent_y = centroids[i]\n","                if area < area_min:\n","                    continue\n","                cv2.rectangle(original_frames[k], (int(cent_x)-w//4, int(cent_y)-h//2), (int(cent_x)+w//4, int(cent_y)+h//2), (0,0,255), 2)\n","        return original_frames\n","    '''\n","    def connect_components(self, frames, original_frames, area_min):\n","        for k, frame in enumerate(frames):\n","            cnt, labels, stats, centroids = cv2.connectedComponentsWithStats(frame)\n","\n","            # connected component의 통계 정보를 기반으로 area 내림차순으로 정렬\n","            sorted_stats = sorted(stats[1:], key=lambda x: x[4], reverse=True)\n","\n","            # 가장 큰 두 개의 박스만 그리기\n","            for i in range(3):\n","                if i >= len(sorted_stats):\n","                    break\n","                (x, y, w, h, area) = sorted_stats[i]\n","                if area < area_min:\n","                    continue\n","                cv2.rectangle(original_frames[k], (x, y), (x+w, y+h), (0,0,255), 2)\n","\n","        return original_frames\n","    '''\n","    def blur(self,frames):\n","        blur_frames = list()\n","        for k, frame in enumerate(frames):\n","            blur_frames.append(cv2.GaussianBlur(frame[:,:,2], (5, 5), 0))\n","        return np.array(blur_frames)\n","\n","    def detect_foreground(self,frames):\n","        lower = np.array([0,140,80], dtype=\"uint8\")\n","        upper = np.array([255,170,158], dtype=\"uint8\")\n","        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n","        binary_frames = list()\n","\n","        for frame in frames:\n","            img_hand = cv2.inRange(frame,lower,upper)\n","            img_hand = cv2.morphologyEx(img_hand, cv2.MORPH_CLOSE, kernel,iterations=2)\n","            binary_frames.append(img_hand)\n","\n","        return np.array(binary_frames,dtype='uint8')\n","\n","    def fit(self):\n","        self.video_to_frames()\n","        hsv_frames = self.frames_rgb_to_ycr(self.frames)\n","        #hsv_frames[:,:,:,2] = self.blur(hsv_frames)\n","        bin_frames = self.detect_foreground(hsv_frames)\n","        self.detected_frames = self.connect_components(bin_frames,self.frames.copy(),20000)\n","\n","    def get_frames(self):\n","        return self.detected_frames\n","\n","    def cvt_to_video(self,output_path):\n","        width = self.cap.get(3)\n","        height = self.cap.get(4)\n","        fps = self.cap.get(5)\n","        fourcc = cv2.VideoWriter_fourcc('F','M','P','4')\n","        video_writer = cv2.VideoWriter(output_path, fourcc, fps, (int(width),int(height)))\n","        for frame in self.frames:\n","            video_writer.write(frame)\n","\n","        video_writer.release()\n","        self.cap.release()\n"],"metadata":{"id":"7twiEzgwrKXu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["detector = Hand_Detection('/content/drive/MyDrive/Konkuk_CV/영상1.mp4')"],"metadata":{"id":"TtEUG1o72A2U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["detector.fit()"],"metadata":{"id":"kMxkhvVm2PQ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["detector.cvt_to_video('/content/drive/MyDrive/Konkuk_CV/output.mp4')"],"metadata":{"id":"NwtjlJnA2QVw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = '/content/drive/MyDrive/Konkuk_CV/영상1.mp4'\n","frames = list()\n","cap = cv2.VideoCapture(path)\n","while cap.isOpened():\n","    run, frame = cap.read()\n","    if not run:\n","        break\n","    img = cv2.cvtColor(frame, cv2.IMREAD_COLOR)\n","    frames.append(img)"],"metadata":{"id":"l8LBrAL2SHrJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def frames_rgb_to_hsv(frames):\n","    g_frames = []\n","    for frame in frames:\n","        g_frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2YCR_CB))\n","    return np.array(g_frames, dtype='uint8')\n","ycr_frames = frames_rgb_to_hsv(frames)"],"metadata":{"id":"yZ7ksXQJfR-7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lower = np.array([0,140,80], dtype=\"uint8\")\n","upper = np.array([255,170,158], dtype=\"uint8\")\n","img_hand = cv2.inRange(ycr_frames[430],lower,upper)\n","cv2_imshow(img_hand)"],"metadata":{"id":"yUf5yuk_fd7_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"g2e_t_Y8kqQ7"},"execution_count":null,"outputs":[]}]}